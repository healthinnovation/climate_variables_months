{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "694fcd6e-e518-4bc9-bed3-b5624089abfe",
   "metadata": {},
   "source": [
    "# RUTINAS DE CONVERSION RASTER TO EXCEL PARA PERU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b982654-ef9a-4ea2-93d5-d34d5a30e600",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95c75c-cad0-4628-86ad-fa5a13e3dd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import rioxarray\n",
    "import xarray as xr\n",
    "from pyhdf.SD import SD, SDC\n",
    "from shapely.geometry import mapping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4c1581-8748-411e-a874-bf63a3f53cb8",
   "metadata": {},
   "source": [
    "# 1.PRECIPITATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6234d5b2-70be-462c-befa-4fbfa36ae4ea",
   "metadata": {},
   "source": [
    "## 2.1.ACUMULADO MENSUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1497e39a-572b-4811-8a7a-1bc53cd5b5a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_precip_monthly(nc_file, shapefile_path, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame pivot con promedio mensual de precipitación por polígono del shapefile.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1️⃣ Leer shapefile y asegurar CRS WGS84\n",
    "    gdf = gpd.read_file(shapefile_path).to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # 2️⃣ Abrir dataset\n",
    "    ds = xr.open_dataset(nc_file)\n",
    "\n",
    "    # Variable precipitación\n",
    "    da = ds['precip']\n",
    "\n",
    "    # Asegurar que tenga CRS\n",
    "    da = da.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Ajustar dims a lon/lat (si no reconoce bien)\n",
    "    da.rio.set_spatial_dims(x_dim=\"longitude\", y_dim=\"latitude\", inplace=True)\n",
    "\n",
    "    # Filtrar por rango de fechas\n",
    "    da = da.sel(time=slice(start_date, end_date))\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    # 3️⃣ Iterar por cada polígono (ej. provincias)\n",
    "    for idx, row in gdf.iterrows():\n",
    "        nombre = row[\"NOMBPROV\"] if \"NOMBPROV\" in gdf.columns else row[\"NOMBDEP\"]  # Ajusta según shapefile\n",
    "        geom = [mapping(row[\"geometry\"])]\n",
    "\n",
    "        try:\n",
    "            clipped = da.rio.clip(geom, gdf.crs, drop=True, all_touched=True)\n",
    "\n",
    "            # Sacar promedio por mes (ya que time es mensual en tu nc)\n",
    "            mean_series = clipped.mean(dim=[\"latitude\", \"longitude\"]).to_pandas()\n",
    "\n",
    "            # Guardar resultados\n",
    "            for date, val in mean_series.items():\n",
    "                results_list.append({\n",
    "                    \"nombre\": nombre,\n",
    "                    \"date\": date,\n",
    "                    \"precip_mean\": float(val) if val == val else pd.NA  # maneja NaN\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en {nombre}: {e}\")\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "    # 4️⃣ Convertir resultados a DataFrame\n",
    "    df = pd.DataFrame(results_list)\n",
    "\n",
    "    # Columna estilo precip_YYYY_MM\n",
    "    df[\"col_name\"] = df[\"date\"].dt.strftime(\"precip_%Y_%m\")\n",
    "\n",
    "    # Pivot table: provincias en filas, fechas en columnas\n",
    "    df_pivot = df.pivot_table(\n",
    "        index=\"nombre\",\n",
    "        columns=\"col_name\",\n",
    "        values=\"precip_mean\",\n",
    "        aggfunc=\"mean\",\n",
    "        fill_value=pd.NA\n",
    "    ).reset_index()\n",
    "\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86685228-2a3c-42b7-a7b8-d0430cb73eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'DEPARTAMENTOS' # DEPARTAMENTOS, PROVINCIAS Y PROVINCIAS\n",
    "nc_file = r\"D:\\Documents_2\\LABORAL\\2025\\INNOVALAB\\data\\prec\\chirps_peru.nc\"\n",
    "shapefile_path = rf\"D:\\Documents_2\\LABORAL\\2025\\INNOVALAB\\shapefile\\{area}_inei_geogpsperu_suyopomalia.shp\"\n",
    "\n",
    "start_date = datetime.datetime(2020, 1, 1)\n",
    "end_date   = datetime.datetime(2024, 12, 31)\n",
    "\n",
    "df_precip_annual = generate_precip_monthly(nc_file, shapefile_path, start_date, end_date)\n",
    "\n",
    "# Guardar CSV\n",
    "df_precip_annual.to_csv(\"precip_provincias_anual.csv\", index=False)\n",
    "print(df_precip_annual.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd693956-900b-45f5-8feb-a134ac3e193f",
   "metadata": {},
   "source": [
    "## # 2.2.ACUMULADO ANUAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3717b3ac-9002-47c7-a5e4-3838af5329b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col_name         nombre  precip_2023  precip_2024\n",
      "0               ABANCAY   960.913635   887.732090\n",
      "1              ACOBAMBA   792.358688   832.228020\n",
      "2               ACOMAYO   674.086234   761.059544\n",
      "3                  AIJA   756.451990   471.805914\n",
      "4         ALTO AMAZONAS  1399.725199  1436.435282\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def generate_precip_annual(nc_file, shapefile_path, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame pivot con acumulado anual de precipitación por polígono del shapefile.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1️⃣ Leer shapefile y asegurar CRS WGS84\n",
    "    gdf = gpd.read_file(shapefile_path).to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # 2️⃣ Abrir dataset\n",
    "    ds = xr.open_dataset(nc_file)\n",
    "    da = ds['precip']\n",
    "\n",
    "    # Asegurar que tenga CRS\n",
    "    da = da.rio.write_crs(\"EPSG:4326\")\n",
    "    da.rio.set_spatial_dims(x_dim=\"longitude\", y_dim=\"latitude\", inplace=True)\n",
    "\n",
    "    # Filtrar por rango de fechas\n",
    "    da = da.sel(time=slice(start_date, end_date))\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    # 3️⃣ Iterar por cada polígono\n",
    "    for idx, row in gdf.iterrows():\n",
    "        nombre = row[\"NOMBPROV\"] if \"NOMBPROV\" in gdf.columns else row[\"NOMBDEP\"]  \n",
    "        geom = [mapping(row[\"geometry\"])]\n",
    "\n",
    "        try:\n",
    "            clipped = da.rio.clip(geom, gdf.crs, drop=True, all_touched=True)\n",
    "\n",
    "            # Serie temporal: promedio espacial\n",
    "            mean_series = clipped.mean(dim=[\"latitude\", \"longitude\"]).to_pandas()\n",
    "\n",
    "            # Agrupar por año y sacar acumulado\n",
    "            annual_series = mean_series.groupby(mean_series.index.year).sum()\n",
    "\n",
    "            # Guardar resultados\n",
    "            for year, val in annual_series.items():\n",
    "                results_list.append({\n",
    "                    \"nombre\": nombre,\n",
    "                    \"year\": year,\n",
    "                    \"precip_annual\": float(val) if val == val else pd.NA\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error en {nombre}: {e}\")\n",
    "\n",
    "    ds.close()\n",
    "\n",
    "    # 4️⃣ Convertir resultados a DataFrame\n",
    "    df = pd.DataFrame(results_list)\n",
    "\n",
    "    # Columna estilo precip_YYYY\n",
    "    df[\"col_name\"] = df[\"year\"].astype(str).apply(lambda y: f\"precip_{y}\")\n",
    "\n",
    "    # Pivot table: provincias en filas, años en columnas\n",
    "    df_pivot = df.pivot_table(\n",
    "        index=\"nombre\",\n",
    "        columns=\"col_name\",\n",
    "        values=\"precip_annual\",\n",
    "        aggfunc=\"mean\",\n",
    "        fill_value=pd.NA\n",
    "    ).reset_index()\n",
    "\n",
    "    return df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d32178-4e14-476e-8a9c-28c8bfbead60",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'DEPARTAMENTOS' # DEPARTAMENTOS, PROVINCIAS Y PROVINCIAS\n",
    "nc_file = r\"D:\\Documents_2\\LABORAL\\2025\\INNOVALAB\\data\\prec\\chirps_peru.nc\"\n",
    "shapefile_path = rf\"D:\\Documents_2\\LABORAL\\2025\\INNOVALAB\\shapefile\\{area}_inei_geogpsperu_suyopomalia.shp\"\n",
    "\n",
    "start_date = datetime.datetime(2023, 1, 1)\n",
    "end_date   = datetime.datetime(2024, 12, 31)\n",
    "\n",
    "df_precip_annual = generate_precip_annual(nc_file, shapefile_path, start_date, end_date)\n",
    "\n",
    "# Guardar CSV\n",
    "df_precip_annual.to_csv(\"precip_distritos_anual_distritos.csv\", index=False)\n",
    "print(df_precip_annual.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486e6e8f-2d94-40eb-978d-70094496cddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1851c758-ed5b-4c12-a796-9742c09d2c38",
   "metadata": {},
   "source": [
    "# 2. LAND SURFACE TEMPERATURE (LST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bd2c311-41ee-4243-ac09-507cc14b8ff1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def generate_LST_dataframe_by_year(data_dir, shapefile_path, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame pivot con promedio de LST MODIS por departamento año por año,\n",
    "    optimizado para no saturar la memoria.\n",
    "    \"\"\"\n",
    "\n",
    "    def file_to_date(filename):\n",
    "        base = os.path.basename(filename)\n",
    "        yday = base.split('.')[1][1:]  # 'A2001335' -> '2001335'\n",
    "        year = int(yday[:4])\n",
    "        day_of_year = int(yday[4:])\n",
    "        return datetime.datetime(year, 1, 1) + datetime.timedelta(day_of_year - 1)\n",
    "\n",
    "    # Leer shapefile\n",
    "    gdf = gpd.read_file(shapefile_path).to_crs(\"EPSG:4326\")\n",
    "\n",
    "    hdf_files = [os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".hdf\")]\n",
    "    files_dict = {file_to_date(f): f for f in hdf_files}\n",
    "\n",
    "    df_final = pd.DataFrame()\n",
    "\n",
    "    for year in range(start_date.year, end_date.year + 1):\n",
    "        print(f\"Procesando año: {year}\")\n",
    "\n",
    "        year_files = [f for date, f in files_dict.items() if date.year == year and start_date <= date <= end_date]\n",
    "\n",
    "        if not year_files:\n",
    "            continue\n",
    "\n",
    "        results_list = []\n",
    "\n",
    "        for file in year_files:\n",
    "            date = file_to_date(file)\n",
    "            hdf = SD(file, SDC.READ)\n",
    "            lst_data = hdf.select('LST_Day_CMG')[:]\n",
    "            lst_c = lst_data * 0.02 - 273.15  # °C\n",
    "\n",
    "            lat = np.linspace(90, -90, lst_c.shape[0])\n",
    "            lon = np.linspace(-180, 180, lst_c.shape[1])\n",
    "\n",
    "            da = xr.DataArray(lst_c, dims=(\"lat\",\"lon\"), coords={\"lat\": lat, \"lon\": lon})\n",
    "            da = da.rename({\"lat\":\"y\",\"lon\":\"x\"}).rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "            da = da.where(da > 0)\n",
    "\n",
    "            for idx, row in gdf.iterrows():\n",
    "                dep = row[\"NOMBDEP\"]\n",
    "                geom = [row[\"geometry\"]]\n",
    "                try:\n",
    "                    lst_clip = da.rio.clip(geom, gdf.crs, drop=True)\n",
    "                    mean_val = float(lst_clip.mean().values)\n",
    "                except Exception:\n",
    "                    mean_val = np.nan\n",
    "                results_list.append({\"NOMBDEP\": dep, \"date\": date, \"LST_mean\": mean_val})\n",
    "\n",
    "        df_year = pd.DataFrame(results_list)\n",
    "        df_year[\"col_name\"] = df_year[\"date\"].dt.strftime(\"LST_mean_%Y%_m\")\n",
    "        df_pivot = df_year.pivot_table(index=\"NOMBDEP\", columns=\"col_name\", values=\"LST_mean\").reset_index()\n",
    "\n",
    "        if df_final.empty:\n",
    "            df_final = df_pivot\n",
    "        else:\n",
    "            df_final = pd.merge(df_final, df_pivot, on=\"NOMBDEP\", how=\"outer\")\n",
    "\n",
    "        del df_year, df_pivot, da, lst_data, lst_c\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3aa101-4ae4-43c8-ae2f-09c294e4a447",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = 'DEPARTAMENTOS' #DEPARTAMENTOS, PROVINCIAS O DISTRITOS\n",
    "data_dir = \"/content/drive/MyDrive/ACCESO_DIRECTO/LST_MODIS/MODIS_LST\"\n",
    "shapefile_path = f\"/content/drive/MyDrive/ACCESO_DIRECTO/SHAPEFILES_PERU/{area}_inei_geogpsperu_suyopomalia.shp\"\n",
    "\n",
    "start_date = datetime.datetime(2024, 1, 1)\n",
    "end_date   = datetime.datetime(2025, 12, 31)\n",
    "\n",
    "df_LST = generate_LST_dataframe_by_year(data_dir, shapefile_path, start_date, end_date)\n",
    "df_LST.to_csv(\"LST_2001_2025_provincia_pivot.csv\", index=False)\n",
    "print(df_LST.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717cbae0-68ea-4b96-97be-40f262972f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b712a3-32bd-4f5c-af31-fc9e6eb255b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "906d9a82-9149-4a1a-ba1f-d02a1ccb11ab",
   "metadata": {},
   "source": [
    "# 3. MONTHLY PM2.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872c1853-0cf5-44ed-8176-6d8b05df1ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_PM25_monthly(data_dir, shapefile_path, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame pivot con promedio mensual de PM2.5 por departamento.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1️⃣ Leer shapefile y asegurar CRS WGS84\n",
    "    gdf = gpd.read_file(shapefile_path).to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # 2️⃣ Listar archivos .nc\n",
    "    nc_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".nc\")])\n",
    "\n",
    "    df_final = pd.DataFrame()\n",
    "\n",
    "    # 3️⃣ Iterar sobre cada archivo\n",
    "    for file in nc_files:\n",
    "        base = os.path.basename(file)\n",
    "        yyyymm = base.split('.')[-2].split('-')[0]\n",
    "        year = int(yyyymm[:4])\n",
    "        month = int(yyyymm[4:6])\n",
    "        file_date = datetime.datetime(year, month, 1)\n",
    "\n",
    "        # Filtrar por rango de fechas\n",
    "        if not (start_date <= file_date <= end_date):\n",
    "            continue\n",
    "\n",
    "        print(f\"Procesando: {file_date.strftime('%Y-%m')}\")\n",
    "\n",
    "        # Abrir dataset\n",
    "        ds = xr.open_dataset(file)\n",
    "        da = ds['PM25']\n",
    "\n",
    "        # Convertir a rioxarray\n",
    "        da = da.rio.write_crs(\"EPSG:4326\")\n",
    "        da.rio.set_spatial_dims(x_dim=\"lon\", y_dim=\"lat\", inplace=True)\n",
    "\n",
    "        results_list = []\n",
    "\n",
    "        # Iterar por cada departamento\n",
    "        for idx, row in gdf.iterrows():\n",
    "            dep = row[\"NOMBDEP\"]\n",
    "            geom = [mapping(row[\"geometry\"])]\n",
    "            try:\n",
    "                clipped = da.rio.clip(geom, gdf.crs, drop=True, all_touched=True)\n",
    "                mean_val = float(clipped.mean().values)\n",
    "            except Exception:\n",
    "                mean_val = pd.NA\n",
    "            results_list.append({\"NOMBDEP\": dep, \"date\": file_date, \"PM25_mean\": mean_val})\n",
    "\n",
    "        ds.close()\n",
    "        del da\n",
    "\n",
    "        # Crear DataFrame y pivot\n",
    "        # Crear DataFrame\n",
    "        df_date = pd.DataFrame(results_list)\n",
    "        df_date[\"col_name\"] = df_date[\"date\"].dt.strftime(\"PM25_mean_%Y_%m\")\n",
    "\n",
    "        # Usar pivot_table para ignorar duplicados y calcular promedio si hay más de un valor\n",
    "        df_pivot = df_date.pivot_table(\n",
    "            index=\"NOMBDEP\",\n",
    "            columns=\"col_name\",\n",
    "            values=\"PM25_mean\",\n",
    "            aggfunc='mean',   # o 'first', 'max', según lo que prefieras\n",
    "            fill_value=pd.NA\n",
    "        ).reset_index()\n",
    "\n",
    "\n",
    "        # Merge con df_final\n",
    "        if df_final.empty:\n",
    "            df_final = df_pivot\n",
    "        else:\n",
    "            df_final = pd.merge(df_final, df_pivot, on=\"NOMBDEP\", how=\"outer\")\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a60a3-b3dc-47fd-8727-80c00877c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "data_dir = r\"D:\\Documents_2\\LABORAL\\2025\\INNOVALAB\\data\\pm25\\Peru_only\"\n",
    "shapefile_path = r\"D:\\Documents_2\\LABORAL\\2025\\INNOVALAB\\shapefile\\DEPARTAMENTOS_inei_geogpsperu_suyopomalia.shp\"\n",
    "\n",
    "start_date = datetime.datetime(1998, 1, 1)\n",
    "end_date   = datetime.datetime(2023, 12, 31)\n",
    "\n",
    "df_PM25 = generate_PM25_monthly(data_dir, shapefile_path, start_date, end_date)\n",
    "\n",
    "# Guardar CSV\n",
    "df_PM25.to_csv(\"PM25_provincias_pivot.csv\", index=False)\n",
    "print(df_PM25.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20b714-7187-448d-ae40-d2229f3b885c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8a7e379-cd6c-45a9-b9d8-9576cb0c15cb",
   "metadata": {},
   "source": [
    "# 4. NO2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64abd2dd-9f9c-412d-9e50-2fe19c2b0ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_NO2_dataframe(data_dir, shapefile_path, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Genera un DataFrame pivot con promedio mensual de NO2 por departamento\n",
    "    usando archivos .tif con nombres tipo NO2_Peru_YYYY_MM.tif\n",
    "    \"\"\"\n",
    "\n",
    "    # Leer shapefile y asegurar CRS WGS84\n",
    "    gdf = gpd.read_file(shapefile_path).to_crs(\"EPSG:4326\")\n",
    "\n",
    "    # Listar archivos .tif\n",
    "    tif_files = sorted([os.path.join(data_dir, f) for f in os.listdir(data_dir) if f.endswith(\".tif\")])\n",
    "\n",
    "    df_final = pd.DataFrame()\n",
    "\n",
    "    for file in tif_files:\n",
    "        base = os.path.basename(file)\n",
    "        \n",
    "        # Extraer año y mes del nombre: NO2_Peru_YYYY_MM.tif\n",
    "        parts = base.split('_')\n",
    "        year = int(parts[2])\n",
    "        month = int(parts[3].split('.')[0])\n",
    "        file_date = datetime.datetime(year, month, 1)\n",
    "\n",
    "        # Filtrar por rango de fechas\n",
    "        if not (start_date <= file_date <= end_date):\n",
    "            continue\n",
    "\n",
    "        print(f\"Procesando: {file_date.strftime('%Y-%m')}\")\n",
    "\n",
    "        # Abrir raster con rioxarray\n",
    "        da = rioxarray.open_rasterio(file)\n",
    "        da = da.rio.write_crs(\"EPSG:4326\")\n",
    "\n",
    "        # Tomar primera banda si existe\n",
    "        if \"band\" in da.dims:\n",
    "            da = da.isel(band=0)\n",
    "\n",
    "        results_list = []\n",
    "\n",
    "        # Iterar por cada departamento\n",
    "        for idx, row in gdf.iterrows():\n",
    "            dep = row[\"NOMBDEP\"]\n",
    "            geom = [mapping(row[\"geometry\"])]\n",
    "            try:\n",
    "                clipped = da.rio.clip(geom, gdf.crs, drop=True, all_touched=True)\n",
    "                mean_val = float(clipped.mean().values)\n",
    "            except Exception:\n",
    "                mean_val = pd.NA\n",
    "            results_list.append({\"NOMBDEP\": dep, \"date\": file_date, \"NO2_mean\": mean_val})\n",
    "\n",
    "        # Crear DataFrame y pivot usando pivot_table para ignorar duplicados\n",
    "        df_date = pd.DataFrame(results_list)\n",
    "        df_date[\"col_name\"] = df_date[\"date\"].dt.strftime(\"NO2_mean_%Y_%m\")\n",
    "        df_pivot = df_date.pivot_table(\n",
    "            index=\"NOMBDEP\",\n",
    "            columns=\"col_name\",\n",
    "            values=\"NO2_mean\",\n",
    "            aggfunc='mean',  # si hay duplicados, tomar promedio\n",
    "            fill_value=pd.NA\n",
    "        ).reset_index()\n",
    "\n",
    "        # Asegurar que todos los departamentos del shapefile estén presentes\n",
    "        df_pivot = gdf[[\"NOMBDEP\"]].merge(df_pivot, on=\"NOMBDEP\", how=\"left\")\n",
    "\n",
    "        # Merge con df_final\n",
    "        if df_final.empty:\n",
    "            df_final = df_pivot\n",
    "        else:\n",
    "            df_final = pd.merge(df_final, df_pivot, on=\"NOMBDEP\", how=\"outer\")\n",
    "\n",
    "    return df_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c8b73e-e1ca-49c0-b01c-4aeb9a6d23ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando: 2024-06\n",
      "Procesando: 2024-07\n",
      "Procesando: 2024-08\n",
      "Procesando: 2024-09\n",
      "Procesando: 2024-10\n",
      "Procesando: 2024-11\n",
      "Procesando: 2024-12\n",
      "    NOMBDEP  NO2_mean_2024_06  NO2_mean_2024_07  NO2_mean_2024_08  \\\n",
      "0  AMAZONAS          0.000004          0.000005          0.000007   \n",
      "1    ANCASH          0.000011          0.000012          0.000014   \n",
      "2  APURIMAC          0.000005          0.000007          0.000008   \n",
      "3  AREQUIPA          0.000010          0.000012          0.000012   \n",
      "4  AYACUCHO          0.000004          0.000006          0.000008   \n",
      "\n",
      "   NO2_mean_2024_09  NO2_mean_2024_10  NO2_mean_2024_11  NO2_mean_2024_12  \n",
      "0          0.000008          0.000007          0.000008          0.000004  \n",
      "1          0.000013          0.000010          0.000011          0.000009  \n",
      "2          0.000007          0.000008          0.000009          0.000006  \n",
      "3          0.000011          0.000011          0.000007          0.000006  \n",
      "4          0.000007          0.000006          0.000006          0.000005  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "area= 'DEPARTAMENTOS' # # CAMBIAR POR PROVINCIAS, DISTRITOS Y DEPARTAMENTOS\n",
    "data_dir = r\"D:\\Documents_2\\LABORAL\\2025\\INNOVALAB\\data\\no2\"\n",
    "shapefile_path = rf\"D:\\Documents_2\\LABORAL\\2025\\INNOVALAB\\shapefile\\{area}_inei_geogpsperu_suyopomalia.shp\" \n",
    "\n",
    "start_date = datetime.datetime(2024, 6, 1)\n",
    "end_date   = datetime.datetime(2024, 12, 31)\n",
    "\n",
    "df_NO2 = generate_NO2_dataframe(data_dir, shapefile_path, start_date, end_date)\n",
    "\n",
    "# Guardar CSV\n",
    "df_NO2.to_csv(\"NO2_2018_2024_provincias_pivot.csv\", index=False)\n",
    "print(df_NO2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b915d5f-4b60-449a-943b-793ed0d422f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
